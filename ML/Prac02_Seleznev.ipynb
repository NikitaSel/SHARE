{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Practice02_Dyachkov.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Oas6DBTD_5X"
      },
      "source": [
        "# Практическое задание 2\n",
        "\n",
        "## Данные о студенте\n",
        "\n",
        "1. **ФИО**: Селезнев Никита Сергеевич\n",
        "2. **Факультет**: физический\n",
        "3. **Курс**: 1 магистратура\n",
        "4. **Группа**: 129м\n",
        "\n",
        "## Замечания\n",
        "\n",
        "* Название ноутбука с реализацией должно иметь шаблон \"**Prac02_Ivanov.ipynb**\" и посылаться на почту mlcoursemm@gmail.com с темой **[CV2021:Prac02]**\n",
        "* Дедлайн будет оговорен в чате курса\n",
        "* Соблюдаем кодекс чести (по нулям и списавшему, и давшему списать)\n",
        "* Можно (и нужно!) применять для реализации только библиотеку **Numpy**\n",
        "* Ничего, крому Numpy, нельзя использовать для реализации \n",
        "* **Keras** используется только для тестирования Вашей реализации\n",
        "* Если какой-то из классов не проходит приведенные тесты, то соответствующее задание не оценивается\n",
        "* Возможно использование дополнительных (приватных) тестов\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTmxFgd1D_5i"
      },
      "source": [
        "## Реализация собственного нейросетевого пакета для запуска и обучения нейронных сетей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7Go32NXD_5j"
      },
      "source": [
        "Задание состоит из трёх частей:\n",
        "1. Реализация прямого вывода нейронной сети (первое практическое задание)\n",
        "2. Реализация градиентов по входу и распространения градиента по сети (back propagation)\n",
        "3. Реализация градиентов по параметрам и метода обратного распространения ошибки с обновлением парметров сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV3K8uAbD_5l"
      },
      "source": [
        "###  1. Реализация вывода собственной нейронной сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfpp5AxED_5m"
      },
      "source": [
        "1.1 Внимательно ознакомьтесь с интерфейсом слоя. Любой слой должен содержать как минимум три метода:\n",
        "- конструктор\n",
        "- прямой вывод \n",
        "- обратный вывод, производные по входу и по параметрам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r06ZM6feD_5m"
      },
      "source": [
        "class Layer(object):\n",
        "    def __init__(self):\n",
        "        self.name = 'Layer'       \n",
        "    def forward(self, input_data):\n",
        "        pass\n",
        "    def backward(self, input_data):\n",
        "        return [self.grad_x(input_data), self.grad_param(input_data)]\n",
        "    \n",
        "    def grad_x(self, input_data):\n",
        "        pass\n",
        "    def grad_param(self, input_data):\n",
        "        return []\n",
        "    \n",
        "    def update_param(self, grads, learning_rate):\n",
        "        pass\n"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d5lqwBAD_5o"
      },
      "source": [
        "1.2 Ниже предствален интерфейс класса  Network. Обратите внимание на реализацию метода predict, который последовательно обрабатывает входные данные слой за слоем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6V8qawMD_5p"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Network(object):\n",
        "    def __init__(self, layers, loss=None):\n",
        "        self.name = 'Network'\n",
        "        self.layers = layers\n",
        "        self.loss = loss\n",
        "    \n",
        "    def forward(self, input_data):\n",
        "        return self.predict(input_data)\n",
        "    \n",
        "    def grad_x(self, input_data, labels):\n",
        "      x = np.ones(input_data.shape)\n",
        "      for layer in self.layers:\n",
        "        x = layer.grad_x(x)\n",
        "      return x\n",
        "    \n",
        "    def grad_param(self, input_data, labels):\n",
        "        pass\n",
        "    def update(self, grad_list, learning_rate):\n",
        "        pass\n",
        "    \n",
        "    def predict(self, input_data):\n",
        "        current_input = input_data\n",
        "        for layer in self.layers:\n",
        "            current_input = layer.forward(current_input)     \n",
        "        return current_input\n",
        "    \n",
        "    def calculate_loss(self, input_data, labels):\n",
        "        return self.loss.forward(self.predict(input_data), labels)\n",
        "    \n",
        "    def train_step(self, input_data, labels, learning_rate=0.001):\n",
        "        grad_list = self.grad_param(input_data, labels)\n",
        "        self.update(grad_list, learning_rate)\n",
        "    \n",
        "    \n",
        "    def fit(self, trainX, trainY, validation_split=0.25, \n",
        "            batch_size=1, nb_epoch=1, learning_rate=0.01):\n",
        "        \n",
        "        train_x, val_x, train_y, val_y = train_test_split(trainX, trainY, \n",
        "                                                          test_size=validation_split,\n",
        "                                                          random_state=42)\n",
        "        for epoch in range(nb_epoch):\n",
        "            #train one epoch\n",
        "            for i in tqdm(range(int(len(train_x)/batch_size))):\n",
        "                batch_x = train_x[i*batch_size: (i+1)*batch_size]\n",
        "                batch_y = train_y[i*batch_size: (i+1)*batch_size]\n",
        "                self.train_step(batch_x, batch_y, learning_rate)\n",
        "            #validate\n",
        "            val_accuracy = self.evaluate(val_x, val_y)\n",
        "            print('%d epoch: val %.2f' %(epoch+1, val_accuracy))\n",
        "            \n",
        "    def evaluate(self, testX, testY):\n",
        "        y_pred = np.argmax(self.predict(testX), axis=1)            \n",
        "        y_true = np.argmax(testY, axis=1)\n",
        "        val_accuracy = np.sum((y_pred == y_true))/(len(y_true))\n",
        "        return val_accuracy"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nURMlR5LD_5p"
      },
      "source": [
        "#### 1.1 (6 баллов) Необходимо реализовать метод forward для вычисления следующих слоёв:\n",
        "\n",
        "- DenseLayer\n",
        "- ReLU\n",
        "- Softmax\n",
        "- FlattenLayer\n",
        "- MaxPooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KslXIGq6D_5q"
      },
      "source": [
        "#импорты\n",
        "import numpy as np"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjz5cNrqD_5r"
      },
      "source": [
        "class DenseLayer(Layer):\n",
        "    def __init__(self, input_dim, output_dim, W_init=None, b_init=None):\n",
        "        self.name = 'Dense'\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        if W_init is None or b_init is None:\n",
        "            self.W = np.random.random((input_dim, output_dim))\n",
        "            self.b = np.zeros(output_dim, 'float32')\n",
        "        else:\n",
        "            self.W = W_init\n",
        "            self.b = b_init\n",
        "    def forward(self, input_data):\n",
        "      return input_data@self.W+self.b\n",
        "    def grad_x(self, input_data): \n",
        "      h, v = input_data.shape\n",
        "      out = np.zeros((h, self.output_dim, self.input_dim))\n",
        "      out += self.W.T[np.newaxis, :]\n",
        "      return out\n",
        "      \n",
        "      return np.zeros((2, 4, 3))\n",
        "    def grad_b(self, input_data):\n",
        "      out = np.zeros((input_data.shape[0], self.output_dim, self.output_dim))\n",
        "      for i in np.arange(input_data.shape[0]):\n",
        "        for j in np.arange(self.output_dim):\n",
        "          for k in np.arange(self.output_dim):\n",
        "             if j == k:\n",
        "               out[i, j, k] = 1\n",
        "      return out\n",
        "    def grad_W(self, input_data):\n",
        "\n",
        "      return input_data\n",
        "    \n",
        "    def update_W(self, grad, learning_rate):\n",
        "        self.W -= learning_rate * np.mean(grad, axis=0).reshape(self.W.shape)\n",
        "    \n",
        "    def update_b(self, grad,  learning_rate):\n",
        "        self.b -= learning_rate * np.mean(grad, axis=0)\n",
        "        \n",
        "    def update_param(self, params_grad, learning_rate):\n",
        "        self.update_W(params_grad[0], learning_rate)\n",
        "        self.update_b(params_grad[1], learning_rate)\n",
        "    \n",
        "    def grad_param(self, input_data):\n",
        "        return [self.grad_W(input_data), self.grad_b(input_data)]\n",
        "    \n",
        "class ReLU(Layer):\n",
        "    def __init__(self):\n",
        "      self.name = 'ReLU'\n",
        "\n",
        "    def forward(self, input_data):\n",
        "      out = np.copy(input_data)\n",
        "      out[out < 0] = 0\n",
        "      return out\n",
        "\n",
        "    def grad_x(self, input_data):\n",
        "      h, v = input_data.shape\n",
        "      out = np.zeros((h, v, v))\n",
        "      for ind_z in np.arange(v):\n",
        "        for ind_x in np.arange(h):\n",
        "          for ind_y in np.arange(v):\n",
        "            if ind_z == ind_y and input_data[ind_x, ind_y] >= 0:\n",
        "              out[ind_x, ind_y, ind_z] = 1\n",
        "      return out\n",
        "    \n",
        "    \n",
        "class Softmax(Layer):\n",
        "    def __init__(self):\n",
        "        self.name = 'Softmax'\n",
        "\n",
        "    def forward(self, input_data):\n",
        "      out = np.exp(input_data) / np.exp(input_data).sum(axis=1)[:, np.newaxis]\n",
        "      return out\n",
        "\n",
        "    def grad_x(self, input_data):\n",
        "      h, v = input_data.shape\n",
        "      out = np.zeros((h, v, v))\n",
        "      for ind_z in np.arange(v):\n",
        "        for ind_x in np.arange(h):\n",
        "          for ind_y in np.arange(v):\n",
        "            if ind_z == ind_y:\n",
        "              out[ind_x, ind_y, ind_z] = np.exp(input_data[ind_x, ind_y]) / np.exp(input_data[ind_x, :]).sum()\n",
        "            out[ind_x, ind_y, ind_z] += -np.exp(input_data[ind_x, ind_z]) *\\\n",
        "                                         np.exp(input_data[ind_x, ind_y]) / \\\n",
        "                                         (np.exp(input_data[ind_x, :]).sum())**2\n",
        "      \n",
        "      return out\n",
        "\n",
        "\n",
        "class FlattenLayer(Layer):\n",
        "    def __init__(self):\n",
        "        self.name = 'Flatten'\n",
        "        \n",
        "    def forward(self, input_data):\n",
        "      batch_size, input_channels_size, height, width = input_data.shape\n",
        "      out = np.zeros((batch_size, input_channels_size*height*width))\n",
        "      for i in np.arange(batch_size):\n",
        "        ind = 0\n",
        "        for j in np.arange(height):\n",
        "          for m in np.arange(width):\n",
        "            for k in np.arange(input_channels_size):\n",
        "              out[i, ind] = input_data[i, k, j , m]\n",
        "              ind += 1\n",
        "      return out\n",
        "               \n",
        "    def grad_x(self):\n",
        "      pass\n",
        "\n",
        "class MaxPooling(Layer):\n",
        "    def __init__(self, pool_size=(2, 2), strides=2):\n",
        "        self.name = 'MaxPooling'\n",
        "        self.pool_size = pool_size\n",
        "        self.strides = 2\n",
        "    def forward(self, input_data):\n",
        "      batch_size, input_channels_size, width, height = input_data.shape\n",
        "      heiht_out = (height - self.pool_size[1]) / self.strides + 1\n",
        "      width_out = (width - self.pool_size[0]) / self.strides + 1\n",
        "      out = np.empty((batch_size, input_channels_size, int(heiht_out), int(width_out)))\n",
        "      for b_i in np.arange(batch_size, dtype=int):\n",
        "        for ch_i in np.arange(input_channels_size, dtype=int):\n",
        "          for h_i in np.arange(heiht_out, dtype=int):\n",
        "              for w_i in np.arange(width_out, dtype=int):\n",
        "                out[b_i, ch_i, h_i, w_i] = np.max(input_data[b_i, \n",
        "                                                  ch_i, \n",
        "                                                  h_i*self.strides:(h_i*self.strides + self.pool_size[1]), \n",
        "                                                  w_i*self.strides:(w_i*self.strides + self.pool_size[0])])\n",
        "\n",
        "       \n",
        "      return out\n",
        "    \n",
        "    def grad_x(self):\n",
        "      pass"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-eY7OUlD_5t"
      },
      "source": [
        "#### 1.2 (3 балла) Реализуйте теперь свёртночный слой   (опционально)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOffyC04D_5t"
      },
      "source": [
        "class Conv2D(Layer):\n",
        "    def __init__(self, kernel_size, input_channels, output_channels, \n",
        "                 kernels_init=None, bias_init=None):\n",
        "        self.name = 'Conv2D'\n",
        "        self.kernel_size = kernel_size\n",
        "        self.input_channels = input_channels\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channels = output_channels\n",
        "        if kernels_init is None or bias_init is None:\n",
        "            pass\n",
        "        else:\n",
        "            self.kernels = kernels_init\n",
        "            self.bias = bias_init\n",
        "            \n",
        "    def forward(self, input_data):\n",
        "      heiht_out = (height - self.kernel_size) / self.stride + 1\n",
        "      width_out = (width - self.kernel_size) / self.stride + 1\n",
        "      out = np.empty((batch_size, self.output_channels, int(heiht_out), int(width_out)))\n",
        "      for b_i in np.arange(batch_size, dtype=int):\n",
        "        for ch_i in np.arange(self.output_channels, dtype=int):\n",
        "          for h_i in np.arange(heiht_out, dtype=int):\n",
        "              for w_i in np.arange(width_out, dtype=int):\n",
        "                out[b_i, ch_i, h_i, w_i] = (input_data[\n",
        "                                                       b_i, \n",
        "                                                       :, \n",
        "                                                       h_i*self.stride:(h_i*self.stride + self.kernel_size), \n",
        "                                                       w_i*self.stride:(w_i*self.stride + self.kernel_size)\n",
        "                                                       ] \\\n",
        "                                            * np.moveaxis(self.kernel[:, :, :, ch_i], -1, 0)\n",
        "                                                       ).sum()\n",
        "\n",
        "      out = out + self.bias.reshape(1, -1, 1, 1)\n",
        "\n",
        "      return out\n",
        "    def grad_x(self):\n",
        "        pass\n",
        "    def grad_kernel(self):\n",
        "        pass"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpGGRSPhD_5t"
      },
      "source": [
        "#### 1.4 Теперь настало время теста. \n",
        "#### Если вы всё сделали правильно, то запустив следующие ячейки у вас должна появиться надпись: Test PASSED\n",
        "\n",
        "Переходить к дальнейшим заданиям не имеем никакого смысла, пока вы не добьётесь прохождение теста\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR5M841ZD_5u"
      },
      "source": [
        "#### Чтение данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESyWAQuRD_5u",
        "outputId": "d5092c39-9fb1-4456-c60a-380847c9625c"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(123)  # for reproducibility\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        " \n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        " \n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 1, 28, 28) (60000, 10) (10000, 1, 28, 28) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1xdFf4fD_5x"
      },
      "source": [
        "#### Подготовка моделей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-Ax8BMRD_5x"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from keras.layers import Convolution2D, Conv2D, MaxPooling2D\n",
        "\n",
        "def get_keras_model():\n",
        "    input_image = Input(shape=(1, 28, 28))\n",
        "    pool1 = MaxPooling2D(pool_size=(2,2), data_format='channels_first')(input_image)\n",
        "    flatten = Flatten()(pool1)\n",
        "    dense1 = Dense(10, activation='softmax')(flatten)\n",
        "    model = Model(inputs=input_image, outputs=dense1)\n",
        "\n",
        "    from keras.optimizers import Adam, SGD\n",
        "    sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=sgd,\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(X_train, Y_train, validation_split=0.25, \n",
        "                        batch_size=32,  epochs=2, verbose=1)\n",
        "    return model"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HldvmCAbD_5y"
      },
      "source": [
        "def get_our_model(keras_model):\n",
        "    maxpool = MaxPooling()\n",
        "    flatten = FlattenLayer()\n",
        "    dense = DenseLayer(196, 10, W_init=keras_model.get_weights()[0],\n",
        "                       b_init=keras_model.get_weights()[1])\n",
        "    softmax = Softmax()\n",
        "    net = Network([maxpool, flatten, dense, softmax])\n",
        "    return net"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_nwMCqzD_5z",
        "outputId": "a0560982-f415-4a5b-a0de-9f9905c28ed1"
      },
      "source": [
        "keras_model = get_keras_model()\n",
        "our_model = get_our_model(keras_model)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.8481 - accuracy: 0.7690 - val_loss: 0.3809 - val_accuracy: 0.8919\n",
            "Epoch 2/2\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.3860 - accuracy: 0.8906 - val_loss: 0.3456 - val_accuracy: 0.9007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i77kUAkD_50"
      },
      "source": [
        "keras_prediction = keras_model.predict(X_test)\n",
        "our_model_prediction = our_model.predict(X_test)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVfHq-GgD_50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511af9ac-ffaa-458f-9807-ee617c891b11"
      },
      "source": [
        "if np.sum(np.abs(keras_prediction - our_model_prediction)) < 0.01:\n",
        "    print('Test PASSED')\n",
        "else:\n",
        "    print('Something went wrong!')"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test PASSED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS97YlF5D_51"
      },
      "source": [
        "### 2. Вычисление производных по входу для слоёв нейронной сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTQYa-7dD_51"
      },
      "source": [
        "#### 2.1 (1 балл) Реализуйте метод forward для класса CrossEntropy\n",
        "Напоминание: $$ crossentropy = L(p, y) =  - \\sum\\limits_i y_i log p_i, $$\n",
        "где вектор $(p_1, ..., p_k) $ -  выход классификационного алгоритма, а $(y_1,..., y_k)$ - правильные метки класса в унарной кодировке (one-hot encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIc3wJkkD_51"
      },
      "source": [
        "class CrossEntropy(object):\n",
        "    def __init__(self, eps=0.00001):\n",
        "        self.name = 'CrossEntropy'\n",
        "        self.eps = eps\n",
        "    \n",
        "    def forward(self, input_data, labels):\n",
        "      \n",
        "      return -np.dot(np.log(input_data), labels.T)\n",
        "    \n",
        "    def calculate_loss(self,input_data, labels):\n",
        "        return self.forward(input_data, labels)\n",
        "    \n",
        "    def grad_x(self, input_data, lables):\n",
        "        return -lables / (input_data + self.eps)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--qwm3-_D_52"
      },
      "source": [
        "#### 2.2 (2 баллa) Реализуйте метод grad_x класса CrossEntropy, который возвращает $\\frac{\\partial L}{\\partial p}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-5vnIthD_52"
      },
      "source": [
        "Проверить работоспособность кода поможет следующий тест:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2vKWH5PD_52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abccc136-1739-4bdd-d7d6-68ba383fa056"
      },
      "source": [
        "def numerical_diff_net(net, x, labels):\n",
        "    eps = 0.00001\n",
        "    right_answer = []\n",
        "    for i in range(len(x[0])):\n",
        "        delta = np.zeros(len(x[0]))\n",
        "        delta[i] = eps\n",
        "        diff = (net.calculate_loss(x + delta, labels) - net.calculate_loss(x-delta, labels)) / (2*eps)\n",
        "        right_answer.append(diff)\n",
        "    return np.array(right_answer).T\n",
        "\n",
        "def test_net(net):\n",
        "    x = np.array([[1, 2, 3], [2, 3, 4]])\n",
        "    labels = np.array([[0.3, 0.2, 0.5], [0.3, 0.2, 0.5]])\n",
        "    num_grad = numerical_diff_net(net, x, labels)\n",
        "    grad = net.grad_x(x, labels)\n",
        "    if np.sum(np.abs(num_grad - grad)) < 0.01:\n",
        "        print('Test PASSED')\n",
        "    else:\n",
        "        print('Something went wrong!')\n",
        "        print('Numerical grad is')\n",
        "        print(num_grad)\n",
        "        print('Your gradiend is ')\n",
        "        print(grad)\n",
        "        \n",
        "loss = CrossEntropy()\n",
        "test_net(loss)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test PASSED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEecJwR6D_52"
      },
      "source": [
        "#### 2.3 (2 балла)   Реализуйте метод grad_x класса Softmax, который возвращает $\\frac{\\partial Softmax}{\\partial x}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3wljBcCD_53"
      },
      "source": [
        "Проверить работоспособность кода поможет следующий тест:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3GIWFfGD_53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee065e2-20a0-429b-b6ca-3b68e3187a54"
      },
      "source": [
        "def numerical_diff_layer(layer, x):\n",
        "    eps = 0.00001\n",
        "    right_answer = []\n",
        "    for i in range(len(x[0])):\n",
        "        delta = np.zeros(len(x[0]))\n",
        "        delta[i] = eps\n",
        "        diff = (layer.forward(x + delta) - layer.forward(x-delta)) / (2*eps)\n",
        "        right_answer.append(diff.T)\n",
        "    return np.array(right_answer).T\n",
        "\n",
        "def test_layer(layer):\n",
        "    x = np.array([[1, 2, 3], [2, -3, 4]])\n",
        "    num_grad = numerical_diff_layer(layer, x)\n",
        "    grad = layer.grad_x(x)\n",
        "    if np.sum(np.abs(num_grad - grad)) < 0.01:\n",
        "        print('Test PASSED')\n",
        "    else:\n",
        "        print('Something went wrong!')\n",
        "        print('Numerical grad is')\n",
        "        print(num_grad)\n",
        "        print('Your gradiend is ')\n",
        "        print(grad)\n",
        "        \n",
        "layer = Softmax()\n",
        "test_layer(layer)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test PASSED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsE5lNAYD_53"
      },
      "source": [
        "#### 2.4 (5 баллов) Реализуйте метод grad_x для классов ReLU и DenseLayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_Fq9fhXD_53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e017ffe-d9a2-45d6-bc8e-59527ca465ef"
      },
      "source": [
        "layer = ReLU()\n",
        "test_layer(layer)"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test PASSED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxQoJHPZD_54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090b3f7f-a365-43a2-80e5-f2575883b4e7"
      },
      "source": [
        "layer = DenseLayer(3,4)\n",
        "test_layer(layer)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test PASSED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW6Yo6SlD_55"
      },
      "source": [
        "#### 2.5 (4 балла) Для класса Network реализуйте метод grad_x, который должен реализовывать взятие производной от лосса по входу"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdWMdZsKD_55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "5e71843e-caab-4da5-a92b-af785b50aba2"
      },
      "source": [
        "net = Network([DenseLayer(3, 10), ReLU(), DenseLayer(10, 3), Softmax()], loss=CrossEntropy())\n",
        "test_net(net)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-158-c16d8d9e0dff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDenseLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDenseLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCrossEntropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-143-198d3d1304d4>\u001b[0m in \u001b[0;36mtest_net\u001b[0;34m(net)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mnum_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_diff_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_grad\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test PASSED'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-157-dd32509d2c05>\u001b[0m in \u001b[0;36mgrad_x\u001b[0;34m(self, input_data, labels)\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-155-3b17f776204e>\u001b[0m in \u001b[0;36mgrad_x\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m       \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mind_z\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQS9akIYD_55"
      },
      "source": [
        "### 3. Реализация градиентов по параметрам и метода обратного распространения ошибки с обновлением парметров сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az0J7gIaD_56"
      },
      "source": [
        "#### 3.1 (4 балла) Реализуйте функции grad_b и grad_W. При подготовке теста grad_W предполагается, что W является отномерным вектором."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5Uuk0iuD_56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b8f182-2015-4861-958a-1d1c02c4ff81"
      },
      "source": [
        "def numerical_grad_b(input_size, output_size, b, W, x):\n",
        "    eps = 0.00001\n",
        "    right_answer = []\n",
        "    for i in range(len(b)):\n",
        "        delta = np.zeros(b.shape)\n",
        "        delta[i] = eps\n",
        "        dense1 = DenseLayer(input_size, output_size, W_init=W, b_init=b+delta)\n",
        "        dense2 = DenseLayer(input_size, output_size, W_init=W, b_init=b-delta)\n",
        "        diff = (dense1.forward(x) - dense2.forward(x)) / (2*eps)\n",
        "        right_answer.append(diff.T)\n",
        "    return np.array(right_answer).T\n",
        "\n",
        "def test_grad_b():\n",
        "    input_size = 3\n",
        "    output_size = 4 \n",
        "    W_init = np.random.random((input_size, output_size))\n",
        "    b_init = np.random.random((output_size,))\n",
        "    x = np.random.random((2, input_size))\n",
        "    \n",
        "    dense = DenseLayer(input_size, output_size, W_init, b_init)\n",
        "    grad = dense.grad_b(x)\n",
        "\n",
        "    num_grad = numerical_grad_b(input_size, output_size, b_init, W_init, x)\n",
        "    if np.sum(np.abs(num_grad - grad)) < 0.01:\n",
        "        print('Test PASSED')\n",
        "    else:\n",
        "        print('Something went wrong!')\n",
        "        print('Numerical grad is')\n",
        "        print(num_grad)\n",
        "        print('Your gradiend is ')\n",
        "        print(grad)\n",
        "\n",
        "test_grad_b()"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test PASSED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSRluxN2D_57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "3d4b7aac-7faf-463c-8305-d6bd7c990ff7"
      },
      "source": [
        "def numerical_grad_W(input_size, output_size, b, W, x):\n",
        "    eps = 0.00001\n",
        "    right_answer = []\n",
        "    for i in range(W.shape[0]):\n",
        "        for j in range(W.shape[1]):\n",
        "            delta = np.zeros(W.shape)\n",
        "            delta[i, j] = eps\n",
        "            dense1 = DenseLayer(input_size, output_size, W_init=W+delta, b_init=b)\n",
        "            dense2 = DenseLayer(input_size, output_size, W_init=W-delta, b_init=b)\n",
        "            diff = (dense1.forward(x) - dense2.forward(x)) / (2*eps)\n",
        "            right_answer.append(diff.T)\n",
        "    return np.array(right_answer).T\n",
        "\n",
        "def test_grad_W():\n",
        "    input_size = 3\n",
        "    output_size = 4 \n",
        "    W_init = np.random.random((input_size, output_size))\n",
        "    b_init = np.random.random((4,))\n",
        "    x = np.random.random((2, input_size))\n",
        "        \n",
        "    dense = DenseLayer(input_size, output_size, W_init, b_init)\n",
        "    grad = dense.grad_W(x)\n",
        "\n",
        "    num_grad = numerical_grad_W(input_size, output_size, b_init, W_init, x)\n",
        "    if np.sum(np.abs(num_grad - grad)) < 0.01:\n",
        "        print('Test PASSED')\n",
        "    else:\n",
        "        print('Something went wrong!')\n",
        "        print('Numerical grad is')\n",
        "        print(num_grad)\n",
        "        print('Your gradiend is ')\n",
        "        print(grad)\n",
        "\n",
        "test_grad_W()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-79ce142fc0d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtest_grad_W\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-107-79ce142fc0d5>\u001b[0m in \u001b[0;36mtest_grad_W\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mnum_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_grad_W\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_grad\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test PASSED'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'NoneType'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQeHimg8D_57"
      },
      "source": [
        "#### 3.2 (4 балла) Полностью реализуйте метод обратного распространения ошибки в функции train_step класса Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXj7MmLzD_57"
      },
      "source": [
        "Рекомендуем реализовать сначала функцию Network.grad_param(), которая возвращает список длиной в количество слоёв и элементом которого является список градиентов по параметрам.\n",
        "После чего, имея список градиентов, написать функцию обновления параметров для каждого слоя. \n",
        "\n",
        "Совет: рекомендуем написать тест для кода подсчета градиента по параметрам, чтобы быть уверенным в том, что градиент через всю сеть считается правильно\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6oD17KCD_57"
      },
      "source": [
        "#### 3.3 Ознакомьтесь с реализацией функции fit класса Network. Запустите обучение модели. Если всё работает правильно, то точность на валидации должна будет возрастать"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43E81mbBD_57",
        "outputId": "374adc6f-4bb5-4ffa-8aaf-18c97f97c443"
      },
      "source": [
        "net = Network([DenseLayer(784, 10), Softmax()], loss=CrossEntropy())\n",
        "trainX = X_train.reshape(len(X_train), -1)\n",
        "net.fit(trainX[::3], Y_train[::3], validation_split=0.25, \n",
        "            batch_size=16, nb_epoch=5, learning_rate=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████| 937/937 [01:30<00:00, 10.32it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 epoch: val 0.72\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████| 937/937 [01:30<00:00, 10.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2 epoch: val 0.80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████| 937/937 [01:31<00:00,  9.95it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3 epoch: val 0.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████| 937/937 [01:34<00:00,  9.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4 epoch: val 0.84\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████| 937/937 [01:33<00:00, 10.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5 epoch: val 0.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5TVJBxpD_58"
      },
      "source": [
        "net = Network([DenseLayer(784, 20), ReLU(), DenseLayer(20, 10), Softmax()], loss=CrossEntropy())\n",
        "trainX = X_train.reshape(len(X_train), -1)\n",
        "net.fit(trainX[::6], Y_train[::6], validation_split=0.25, \n",
        "            batch_size=16, nb_epoch=5, learning_rate=0.001)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFU5RQ_4D_58"
      },
      "source": [
        "#### 3.5 (2 балла) Продемонстрируйте, что ваша реализация позволяет обучать более глубокие нейронные сети "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z04-D2KLD_59"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}